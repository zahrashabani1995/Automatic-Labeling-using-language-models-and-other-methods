# Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
!pip install sentence-transformers parsivar scikit-learn numpy pandas openpyxl

import pandas as pd
import numpy as np
import re
import io
import matplotlib.pyplot as plt
import seaborn as sns
import math

from google.colab import files
from parsivar import Normalizer, Tokenizer 
from sentence_transformers import SentenceTransformer
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC 
from sklearn.metrics import (
    accuracy_score, confusion_matrix, f1_score, matthews_corrcoef, 
    cohen_kappa_score, mean_absolute_error, recall_score, roc_auc_score, roc_curve
)
from sklearn.preprocessing import LabelBinarizer

# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ---

print("Ù„Ø·ÙØ§ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ù„ÛŒØ¨Ù„â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯:")
uploaded = files.upload()
file_name = next(iter(uploaded))

df = pd.read_excel(io.BytesIO(uploaded[file_name]))
df.columns = ['text', 'label'] 
print(f"âœ… ÙØ§ÛŒÙ„ Ø¨Ø§ {len(df)} Ø³Ø·Ø± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯.")

# --- Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ (Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Parsivar) ---
normalizer = Normalizer()
tokenizer = Tokenizer()
stop_words = set([
    "Ø§Ø²", "Ø¨Ù‡", "Ø¨Ø§", "Ø¯Ø±", "Ø¨Ø±", "Ø¨Ø±Ø§ÛŒ", "Ú©Ù‡", "Ùˆ", "ÛŒØ§", "ÛŒÚ©", "Ø§ÛŒÙ†", "Ø¢Ù†",
    "Ù‡Ø§", "Ø§ÛŒ", "Ø±Ø§", "Ù‡Ù…", "Ø¨ÙˆØ¯", "Ø§Ø³Øª", "Ø¨Ø§Ø´Ø¯", "Ø´Ø¯", "Ù…ÛŒ", "Ù‡Ù…ÛŒÙ†", "Ú†Ù†ÛŒÙ†",
    "Ø§Ù…Ø§", "Ø§Ú¯Ø±", "Ú†ÙˆÙ†", "ØªØ§", "Ù…Ø§", "Ù…Ù†", "ØªÙˆ", "Ø§Ùˆ", "Ø´Ù…Ø§", "Ø§ÛŒØ´Ø§Ù†"
])

def preprocess_text(text):
    """ØªØ§Ø¨Ø¹ Ø¬Ø§Ù…Ø¹ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Parsivar"""
    if pd.isna(text) or not text:
        return ""
    
    text = normalizer.normalize(str(text))
    text = re.sub(r'http\S+|www\S+|#\w+|@\w+', '', text, flags=re.MULTILINE)
    text = re.sub(r'[^\u0600-\u06FF\s]', '', text) 
    text = re.sub(r'\s+', ' ', text).strip()
    
    tokens = tokenizer.tokenize_words(text)
    filtered_tokens = [token for token in tokens if token not in stop_words and len(token) > 1]
    
    return ' '.join(filtered_tokens)

# Ø§Ø¹Ù…Ø§Ù„ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´
df['cleaned_text'] = df['text'].apply(preprocess_text)
# --- Ø§Ù„Ù: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ Ø¨Ø§ SBERT ---
texts = df['cleaned_text'].tolist()
y = df['label'].values

print("ğŸš€ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ SBERT Ø¢ØºØ§Ø² Ø´Ø¯...")
# Ø§Ù†ØªØ®Ø§Ø¨ ÛŒÚ© Ù…Ø¯Ù„ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡ Ù‚ÙˆÛŒ Ú©Ù‡ Ø¨Ø±Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ Ù‡Ù… Ø¨Ù‡ Ø®ÙˆØ¨ÛŒ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯
model_name = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2' 
sbert_model = SentenceTransformer(model_name)
print(f"âœ… Ù…Ø¯Ù„ SBERT ({model_name}) Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯.")

print("ğŸš€ ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
# ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø¯Ø§Ø± Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù…ÛŒ Ù…ØªÙˆÙ† Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡
X_sbert = sbert_model.encode(texts, show_progress_bar=True) 

print(f"âœ… ØªÙˆÙ„ÛŒØ¯ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯. Ø§Ø¨Ø¹Ø§Ø¯ ÙˆÛŒÚ˜Ú¯ÛŒ (X_sbert): {X_sbert.shape}")

# --- Ø¨: ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Û¶Û°:Û³Û°:Û±Û°) ---
X_train, X_temp, y_train, y_temp = train_test_split(
    X_sbert, y, test_size=0.4, random_state=42, stratify=y
)
validation_ratio_from_temp = 0.25 
X_test, X_val, y_test, y_val = train_test_split(
    X_temp, y_temp, 
    test_size=validation_ratio_from_temp, 
    random_state=42, 
    stratify=y_temp
)

print(f"âœ… ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ø³Ø¨Øª Û¶Û°:Û³Û°:Û±Û° Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯: Train: {len(X_train)}, Test: {len(X_test)}, Validation: {len(X_val)}")

# --- Ø¬: Ø¢Ù…ÙˆØ²Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ SVM ---
svm_classifier = SVC(
    kernel='linear', 
    C=1.0, 
    random_state=42, 
    probability=True
)

print("\nğŸš€ Ø¢Ù…ÙˆØ²Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ SVM Ø¨Ø§ Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ SBERT Ø¢ØºØ§Ø² Ø´Ø¯...")
svm_classifier.fit(X_train, y_train)
print("âœ… Ø¢Ù…ÙˆØ²Ø´ Ø·Ø¨Ù‚Ù‡â€ŒØ¨Ù†Ø¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")

# --- Ø¯: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª ---
y_pred = svm_classifier.predict(X_test)
y_prob = svm_classifier.predict_proba(X_test)
# --- ØªØ¹Ø±ÛŒÙ Ù†Ø§Ù… Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ ---
LABELS = [0, 1, 2]
CLASS_NAMES = {
    0: 'Non-related', 
    1: 'Indirect Suicide Signs', 
    2: 'Direct Suicide Signs'
}

# --- Ø§Ù„Ù: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø§Ú©Ø³Ù„ ---

# Û±. Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
accuracy = accuracy_score(y_test, y_pred)
kappa = cohen_kappa_score(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
f1_macro = f1_score(y_test, y_pred, average='macro')
f1_weighted = f1_score(y_test, y_pred, average='weighted')
mae = mean_absolute_error(y_test, y_pred)
rmse = math.sqrt(np.mean((y_test - y_pred)**2)) 
recall_macro = recall_score(y_test, y_pred, average='macro')

# Û². AUC-ROC (OVR)
lb = LabelBinarizer()
y_test_binarized = lb.fit_transform(y_test)
try:
    auc_roc_ovr = roc_auc_score(y_test_binarized, y_prob, multi_class='ovr')
except ValueError:
    auc_roc_ovr = "N/A"

# Û³. Specificity (Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ø§Ø³)
tn_rate = {}
for i in LABELS:
    tn, fp, fn, tp = confusion_matrix(y_test == i, y_pred == i).ravel()
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0 
    tn_rate[i] = specificity

# Û´. Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø§Ú©Ø³Ù„
results = {
    'Metric': [
        'Accuracy', "Cohen's Kappa", 'MCC', 'F1-score (Macro)', 
        'F1-score (Weighted)', 'MAE', 'RMSE', 'Macro Average Recall (Sensitivity)', 
        'AUC-ROC (OVR)'
    ],
    'Value': [
        accuracy, kappa, mcc, f1_macro, f1_weighted, mae, rmse, 
        recall_macro, auc_roc_ovr
    ]
}
results_df = pd.DataFrame(results)

for label, name in CLASS_NAMES.items():
    results_df = pd.concat([results_df, pd.DataFrame({
        'Metric': [f'Specificity ({name})'],
        'Value': [tn_rate[label]]
    })], ignore_index=True)

output_results_file = 'SBERT_SVM_Evaluation_Metrics.xlsx'
results_df.to_excel(output_results_file, index=False)
files.download(output_results_file)
print("âœ… Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")

# --- Ø¨: ØªØ±Ø³ÛŒÙ… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ ---

# Û±. Confusion Matrix
cm = confusion_matrix(y_test, y_pred, labels=LABELS)
cm_df = pd.DataFrame(cm, index=CLASS_NAMES.values(), columns=CLASS_NAMES.values())

plt.figure(figsize=(8, 6))
sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', linewidths=.5, linecolor='black')
plt.title('Confusion Matrix (SBERT+SVM)', fontsize=16)
plt.ylabel('True Label (Actual)', fontsize=14)
plt.xlabel('Predicted Label', fontsize=14)
plt.show()


# Û². AUC-ROC Curve per Class
plt.figure(figsize=(10, 7))

for i in range(len(LABELS)):
    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])
    auc_score = roc_auc_score(y_test_binarized[:, i], y_prob[:, i])
    
    plt.plot(fpr, tpr, 
             label=f"Class {LABELS[i]} ({CLASS_NAMES[LABELS[i]]}) AUC = {auc_score:.2f}")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)
plt.ylabel('True Positive Rate (Recall/Sensitivity)', fontsize=12)
plt.title('AUC-ROC Curve per Class (One-vs-Rest Strategy)', fontsize=16)
plt.legend(loc="lower right")
plt.grid(True)
plt.show()


print("\nâœ… ØªÙ…Ø§Ù…ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ ØªÙˆÙ„ÛŒØ¯ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯.")
print("âœ… Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø¨Ø§ Parsivar Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")
