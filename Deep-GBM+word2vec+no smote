# =================================================================
# Ø³Ù„ÙˆÙ„ Û±: Ù†ØµØ¨ØŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒØŒ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø§ÛŒÙ…Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ù†Ù‡Ø§ÛŒÛŒ (Ø¨Ø±Ø§ÛŒ XGBoost)
# =================================================================
%%time

# --- Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² ---
# Ù†ØµØ¨ ØªÙ…Ø§Ù… Ù¾Ú©ÛŒØ¬â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø´Ø§Ù…Ù„ parsivarØŒ imbalanced-learnØŒ gensim Ùˆ xgboost
!pip install pandas numpy scikit-learn parsivar matplotlib seaborn imbalanced-learn openpyxl gensim xgboost --quiet

# --- Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² ---
import pandas as pd
import numpy as np
import re
import io
import time
import math
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files

# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ
from parsivar import Normalizer, Tokenizer 
import gensim.models
import gensim.models.fasttext as FastTextModel 

# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Scikit-learn Ùˆ Imbalanced-learn
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score, confusion_matrix, f1_score, matthews_corrcoef, 
    cohen_kappa_score, recall_score, make_scorer, roc_auc_score, roc_curve, 
    precision_recall_fscore_support, precision_score, log_loss, mean_absolute_error,
    brier_score_loss
)
from sklearn.preprocessing import LabelBinarizer
from sklearn.pipeline import Pipeline
from sklearn.calibration import calibration_curve
from imblearn.pipeline import Pipeline as ImbPipeline 
from imblearn.over_sampling import SMOTE 
from sklearn.feature_extraction.text import TfidfVectorizer 
from sklearn.base import BaseEstimator, TransformerMixin # Ø¨Ø±Ø§ÛŒ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø³ÙØ§Ø±Ø´ÛŒ

# ğŸš¨ Ø§ÛŒÙ…Ù¾ÙˆØ±Øª XGBoost
from xgboost import XGBClassifier


# --- ØªÙˆØ§Ø¨Ø¹ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§Ø±Ø³ÛŒ ---
normalizer = Normalizer()
tokenizer = Tokenizer()

def preprocess_text(text):
    """Ø§Ø¹Ù…Ø§Ù„ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ùˆ ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡ Ø±ÙˆÛŒ Ù…ØªÙ† ÙØ§Ø±Ø³ÛŒ."""
    if pd.isna(text):
        return ""
    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙØ§Ø±Ø³ÛŒ (Ø§ØµÙ„Ø§Ø­ Ù†ÛŒÙ…â€ŒÙØ§ØµÙ„Ù‡ØŒ Ú©â€ŒÙ‡Ø§ØŒ ÛŒâ€ŒÙ‡Ø§ Ùˆ...)
    text = normalizer.normalize(text)
    # Ø­Ø°Ù Ø§Ø¹Ø¯Ø§Ø¯
    text = re.sub(r'[Û°-Û¹]', '', text) 
    text = re.sub(r'[0-9]', '', text) 
    # Ø­Ø°Ù Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ
    text = re.sub(r'[^\w\s]', '', text) 
    # Ø­Ø°Ù Ø²ÛŒØ±Ø®Ø·â€ŒÙ‡Ø§
    text = re.sub(r'_', '', text) 
    # ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø­Ø°Ù ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ
    tokens = [token for token in tokenizer.tokenize_words(text) if token.strip()]
    return " ".join(tokens)


# --- Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ùˆ Ø§Ø¹Ù…Ø§Ù„ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ ---
print("\nğŸ”„ Ù„Ø·ÙØ§ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ù„ÛŒØ¨Ù„â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ (Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ 'text' Ùˆ 'label') Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯.")
try:
    # Ø¨Ø®Ø´ Ø¢Ù¾Ù„ÙˆØ¯
    uploaded = files.upload()
    file_name = next(iter(uploaded))
    df = pd.read_excel(io.BytesIO(uploaded[file_name]))
    
    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ù†Ø§Ù… Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ùˆ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú©
    df.columns = df.columns.str.lower()
    if 'text' not in df.columns or 'label' not in df.columns:
         raise ValueError("ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ø§ÛŒØ¯ Ø´Ø§Ù…Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ 'text' Ùˆ 'label' Ø¨Ø§Ø´Ø¯ (Ø¨Ø¯ÙˆÙ† Ø­Ø³Ø§Ø³ÛŒØª Ø¨Ù‡ Ø­Ø±ÙˆÙ Ø¨Ø²Ø±Ú¯/Ú©ÙˆÚ†Ú©).")

    # Ø­Ø°Ù Ø³Ø·Ø±Ù‡Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒ NaN Ø¯Ø± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
    df.dropna(subset=['text', 'label'], inplace=True)
    
    # Ø§Ø¹Ù…Ø§Ù„ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´
    df['cleaned_text'] = df['text'].apply(preprocess_text)
    
    # ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¹Ø¯Ø¯ ØµØ­ÛŒØ­
    y_labels = df['label'].astype(int).values 
    LABELS = np.unique(y_labels).tolist() 
    
    # ğŸ’¡ ØªØ¹Ø±ÛŒÙ Ù†Ø§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ (Ø¨Ø± Ø§Ø³Ø§Ø³ Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ Ø´Ù…Ø§)
    CLASS_NAMES = {
        0: 'Non-related', 
        1: 'Indirect Suicide Signs', 
        2: 'Direct Suicide Signs'
    }
    
    # --- ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (60% Ø¢Ù…ÙˆØ²Ø´ØŒ 30% Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒØŒ 10% ØªØ³Øª) ---
    X = df['cleaned_text']
    y = y_labels

    # 1. ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Training (60%) Ùˆ Temp (40%)
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y, test_size=0.4, random_state=42, stratify=y
    )

    # 2. ØªÙ‚Ø³ÛŒÙ… Temp Ø¨Ù‡ Validation (30%) Ùˆ Test (10%)
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
    )

    print(f"\nâœ… ÙØ§ÛŒÙ„ Ø¨Ø§ {len(df)} Ø³Ø·Ø± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø®ÙˆØ§Ù†Ø¯Ù‡ Ø´Ø¯ Ùˆ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ ØªÙ‚Ø³ÛŒÙ… Ø´Ø¯.")
    print(f"\nğŸ“Š ØªÙˆØ²ÛŒØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§:")
    print(f"Ø¢Ù…ÙˆØ²Ø´ (Train): {len(X_train)} ({len(X_train) / len(df) * 100:.1f}%)")
    print(f"Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ (Validation): {len(X_val)} ({len(X_val) / len(df) * 100:.1f}%)")
    print(f"ØªØ³Øª (Test): {len(X_test)} ({len(X_test) / len(df) * 100:.1f}%)")

except Exception as e:
    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÛŒØ§ Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„: {e}")
    # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø´ÙˆØ¯ØŒ Ø§Ø¬Ø±Ø§ÛŒ Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Ù…ØªÙˆÙ‚Ù Ù…ÛŒâ€ŒØ´ÙˆØ¯
    raise 
# =================================================================
# Ø³Ù„ÙˆÙ„ Û²: Ù…Ø¯Ù„Ø³Ø§Ø²ÛŒ XGBoost Ø¨Ø§ Word2Vec Ùˆ Ø¨Ø¯ÙˆÙ† Ù‡ÛŒÚ† Ú¯ÙˆÙ†Ù‡ Ù…ØªØ¹Ø§Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ
# =================================================================
%%time

MODEL_NAME = "XGBoost_Word2Vec_NoBalance" 

# --- Û±. ØªØ¹Ø±ÛŒÙ Word2Vec Embedding (Ù…Ø¬Ø¯Ø¯) ---

class Word2VecVectorizer(BaseEstimator, TransformerMixin):
    """ØªØ¨Ø¯ÛŒÙ„ Ú©Ù†Ù†Ø¯Ù‡ Ù…ØªÙ† Ø¨Ù‡ Ø¨Ø±Ø¯Ø§Ø± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ú©Ù„Ù…Ø§Øª Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Gensim Word2Vec."""
    
    def __init__(self, vector_size=100, min_count=1, window=5, workers=4):
        self.vector_size = vector_size
        self.min_count = min_count
        self.window = window
        self.workers = workers
        self.word2vec_model = None

    def fit(self, X, y=None):
        # Word2Vec Ù†ÛŒØ§Ø² Ø¨Ù‡ Ù„ÛŒØ³Øª ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¯Ø§Ø±Ø¯
        tokenized_sentences = [text.split() for text in X]
        
        print(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø¢Ù…ÙˆØ²Ø´ Word2Vec Ø¨Ø§ vector_size={self.vector_size}...")
        
        # ğŸš¨ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ØªØ¯ Word2Vec
        self.word2vec_model = gensim.models.Word2Vec(
            sentences=tokenized_sentences,
            vector_size=self.vector_size,
            min_count=self.min_count,
            window=self.window,
            workers=self.workers,
            seed=42
        )
        # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„
        self.word2vec_model.train(tokenized_sentences, total_examples=len(tokenized_sentences), epochs=10)
        print("âœ… Ø¢Ù…ÙˆØ²Ø´ Word2Vec Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")
        return self

    def transform(self, X):
        tokenized_sentences = [text.split() for text in X]
        
        def get_mean_vector(tokens):
            # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ú©Ù„Ù…Ø§ØªÛŒ Ú©Ù‡ Ø¯Ø± ÙˆØ§Ú˜Ù‡â€ŒÙ†Ø§Ù…Ù‡ Ù…Ø¯Ù„ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯
            vectors = [self.word2vec_model.wv[word] for word in tokens if word in self.word2vec_model.wv]
            if vectors:
                # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø¨Ø±Ø¯Ø§Ø±Ù‡Ø§ÛŒ Ú©Ù„Ù…Ø§Øª
                return np.mean(vectors, axis=0)
            else:
                # Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† ÛŒÚ© Ø¨Ø±Ø¯Ø§Ø± ØµÙØ± Ø¯Ø± ØµÙˆØ±Øª Ø®Ø§Ù„ÛŒ Ø¨ÙˆØ¯Ù† Ø³Ù†Ø¯ ÛŒØ§ OOV Ø¨ÙˆØ¯Ù† Ù‡Ù…Ù‡ Ú©Ù„Ù…Ø§Øª
                return np.zeros(self.vector_size)

        return np.array([get_mean_vector(tokens) for tokens in tokenized_sentences])


# --- Û². ØªØ¹Ø±ÛŒÙ Ø§Ø¬Ø²Ø§ÛŒ Pipeline (Ø¨Ø¯ÙˆÙ† Sampler) ---
word2vec_vectorizer = Word2VecVectorizer(vector_size=100) 

xgb_classifier = XGBClassifier(
    objective='multi:softprob', 
    eval_metric='mlogloss', 
    use_label_encoder=False, 
    random_state=42
) 

# ğŸš¨ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Pipeline Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ (ÙØ§Ù‚Ø¯ Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ù…ØªØ¹Ø§Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ)
pipeline = Pipeline([
    ('embedding', word2vec_vectorizer),
    ('clf', xgb_classifier) 
])

# --- Û³. ØªÙ†Ø¸ÛŒÙ… Ù‡Ø§ÛŒÙ¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ (Grid Search) ---
param_grid = {
    # Ù‡Ø§ÛŒÙ¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Word2Vec
    'embedding__vector_size': [100, 200], 
    # Ù‡Ø§ÛŒÙ¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ XGBoost
    'clf__n_estimators': [100, 200], 
    'clf__max_depth': [5, 7], 
    'clf__learning_rate': [0.1, 0.2] 
}

f1_macro_scorer = make_scorer(f1_score, average='macro')

print("ğŸš€ Ø´Ø±ÙˆØ¹ Grid Search Ùˆ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„...")
grid_search_start = time.time()

# Ø§Ø¬Ø±Ø§ÛŒ Grid Search
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    scoring=f1_macro_scorer,
    cv=3, 
    verbose=1,
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

grid_search_end = time.time()
training_time = grid_search_end - grid_search_start

best_model = grid_search.best_estimator_
best_params = grid_search.best_params_

print(f"\nâœ… Ø¢Ù…ÙˆØ²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯. Ø²Ù…Ø§Ù† Ø¢Ù…ÙˆØ²Ø´: {training_time:.2f} Ø«Ø§Ù†ÛŒÙ‡")
print(f"âœ… Ø¨Ù‡ØªØ±ÛŒÙ† Ù‡Ø§ÛŒÙ¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡: {best_params}")

# Û´. Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Test
y_pred = best_model.predict(X_test)
y_prob = best_model.predict_proba(X_test)

print("\nØ²Ù…Ø§Ù† Ú©Ù„ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ù„ÙˆÙ„ Û² (Ù…Ø¯Ù„Ø³Ø§Ø²ÛŒ):")
# =================================================================
# Ø³Ù„ÙˆÙ„ Û³: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø±ÛŒ Ø¬Ø§Ù…Ø¹ (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Ø³Ø§Ø²Ú¯Ø§Ø±)
# =================================================================
%%time

from sklearn.metrics import log_loss, mean_absolute_error, roc_auc_score, precision_recall_fscore_support, confusion_matrix
import pandas as pd
from sklearn.base import BaseEstimator
from sklearn.preprocessing import LabelBinarizer
from sklearn.feature_extraction.text import TfidfVectorizer 
from imblearn.pipeline import Pipeline as ImbPipeline
import numpy as np
from google.colab import files # Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ù…Ø¬Ø¯Ø¯

# --- Ø§Ù„Ù: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ú©Ù„ÛŒ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
# (Ú©Ø¯Ù‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ accuracyØŒ f1_macroØŒ loglossØŒ AUC Ùˆ... Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯)
accuracy = accuracy_score(y_test, y_pred)
f1_macro = f1_score(y_test, y_pred, average='macro')
# ... (Ø¨Ù‚ÛŒÙ‡ Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ùˆ Ø§ÛŒØ¬Ø§Ø¯ df_overall)
recall_macro = recall_score(y_test, y_pred, average='macro')
precision_macro = precision_score(y_test, y_pred, average='macro')
kappa = cohen_kappa_score(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
logloss = log_loss(y_test, y_prob)
mae = mean_absolute_error(y_test, y_pred)

lb = LabelBinarizer()
y_test_binarized = lb.fit_transform(y_test)

try:
    if len(LABELS) > 2:
        auc_roc_ovr = roc_auc_score(y_test_binarized, y_prob, multi_class='ovr')
        auc_roc_ovo = roc_auc_score(y_test, y_prob, multi_class='ovo')
    elif len(LABELS) == 2:
        auc_roc_ovr = roc_auc_score(y_test_binarized, y_prob[:, 1])
        auc_roc_ovo = "N/A (Binary)"
    else:
        auc_roc_ovr = "N/A"
        auc_roc_ovo = "N/A"
except Exception: 
    auc_roc_ovr = "Error"
    auc_roc_ovo = "Error"

results_overall = {
    'Model': [MODEL_NAME], 'Embedding': ['Word2Vec'],
    'Accuracy': [accuracy], 'F1-Macro': [f1_macro], 'Recall-Macro': [recall_macro],
    'Precision-Macro': [precision_macro], 'Kappa': [kappa], 'MCC': [mcc],
    'AUC-ROC (OVR)': [auc_roc_ovr], 'AUC-ROC (OVO)': [auc_roc_ovo],
    'Log Loss': [logloss], 'MAE': [mae],
    'Training Time (s)': [training_time]
}
df_overall = pd.DataFrame(results_overall)

# --- Ø¨: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ ØªÙÚ©ÛŒÚ© Ø´Ø¯Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ù„Ø§Ø³ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
precision_c, recall_c, f1_c, support_c = precision_recall_fscore_support(
    y_test, y_pred, labels=LABELS, average=None
)
# (Ú©Ø¯Ù‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ SpecificityØŒ NPV Ùˆ AUC Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ø§Ø³ Ùˆ Ø§ÛŒØ¬Ø§Ø¯ df_class_metrics Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯)
specificity_c = []
npv_c = []
auc_c = []

for i, label in enumerate(LABELS):
    cm_binary = confusion_matrix(y_test == label, y_pred == label, labels=[True, False])
    
    if cm_binary.size == 4:
        tn, fp, fn, tp = cm_binary.ravel()
    else:
        tn, fp, fn, tp = 0, 0, 0, 0

    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0 
    specificity_c.append(specificity)

    npv = tn / (tn + fn) if (tn + fn) > 0 else 0 
    npv_c.append(npv)
    
    try:
        auc_class = roc_auc_score(y_test_binarized[:, i], y_prob[:, i])
        auc_c.append(auc_class)
    except Exception:
        auc_c.append(np.nan)

df_class_metrics = pd.DataFrame({
    'Class': [CLASS_NAMES.get(i, f'Class {i}') for i in LABELS],
    'Precision': precision_c,
    'Recall (Sensitivity)': recall_c, 
    'Specificity': specificity_c,
    'F1-Score': f1_c,
    'NPV (Negative Predictive Value)': npv_c,
    'AUC (OVR)': auc_c,
    'Support': support_c
})

df_class_metrics.loc[len(df_class_metrics)] = {
    'Class': 'Macro Average',
    'Precision': precision_macro, 
    'Recall (Sensitivity)': recall_macro, 
    'F1-Score': f1_macro, 
    'Specificity': np.mean(specificity_c), 
    'NPV (Negative Predictive Value)': np.mean(npv_c),
    'AUC (OVR)': auc_roc_ovr if isinstance(auc_roc_ovr, float) else np.nan,
    'Support': np.sum(support_c)
}


# --- Ø¬: Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ§Ú˜Ú¯Ø§Ù† Ú©Ù„ÛŒØ¯ÛŒ (ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Û³ - Ù…Ù†Ø·Ù‚ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡) ---

key_words_df = pd.DataFrame()
print("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ§Ú˜Ú¯Ø§Ù† Ú©Ù„ÛŒØ¯ÛŒ...")

# ğŸš¨ ØªØ¹ÛŒÛŒÙ† Ù†Ø§Ù… Ù…Ø±Ø­Ù„Ù‡ Embedding Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†ÙˆØ¹ Vectorizer
try:
    if 'tfidf' in best_model.named_steps:
        # Ù…Ø¯Ù„ TF-IDF Ø§Ø³Øª
        embedding_step_name = 'tfidf'
        vectorizer = best_model.named_steps[embedding_step_name]
        is_word_embedding = False
    elif 'embedding' in best_model.named_steps:
        # Ù…Ø¯Ù„ Word2Vec/FastText Ø§Ø³Øª
        embedding_step_name = 'embedding'
        vectorizer = best_model.named_steps[embedding_step_name]
        is_word_embedding = True
    else:
        raise KeyError("Ù…Ø±Ø­Ù„Ù‡ Vectorizer Ø¯Ø± Pipeline ÛŒØ§ÙØª Ù†Ø´Ø¯ (Ù†Ù‡ 'tfidf' Ùˆ Ù†Ù‡ 'embedding').")

    classifier = best_model.named_steps['clf']

    if is_word_embedding:
        # Ø§Ú¯Ø± Word2Vec ÛŒØ§ FastText Ø¨Ø§Ø´Ø¯: ØªØ­Ù„ÛŒÙ„ ÙˆÛŒÚ˜Ú¯ÛŒ Ù‚Ø§Ø¨Ù„ Ø§Ù†Ø¬Ø§Ù… Ù†ÛŒØ³Øª.
        key_words_df = pd.DataFrame({
            'Feature': ['N/A (Word/FastText Embeddings are dense vectors)'],
            'Weight': ['Key word analysis not applicable for this embedding type.']
        }) 
        print("âš ï¸ Ø§Ø®Ø·Ø§Ø±: ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ú˜Ú¯Ø§Ù† Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ EmbeddingÙ‡Ø§ÛŒ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ø­Ø°Ù Ø´Ø¯.")

    elif not is_word_embedding:
        # Ø§Ú¯Ø± TF-IDF Ø¨Ø§Ø´Ø¯: ØªØ­Ù„ÛŒÙ„ ÙˆÛŒÚ˜Ú¯ÛŒ Ø±Ø§ Ø§Ù†Ø¬Ø§Ù… Ø¨Ø¯Ù‡.
        feature_names = vectorizer.get_feature_names_out()
        
        if hasattr(classifier, 'feature_importances_'):
            # Ø¨Ø±Ø§ÛŒ XGBoost
            feature_importances = classifier.feature_importances_
            feature_data = list(zip(feature_names, feature_importances))
            feature_data.sort(key=lambda x: x[1], reverse=True)
            top_features = feature_data[:50]
            key_words_df = pd.DataFrame(top_features, columns=['Feature', 'Importance/Weight'])
            key_words_df['Model Type'] = 'Tree-based (Feature Importance)'
            
        elif hasattr(classifier, 'coef_'):
            # Ø¨Ø±Ø§ÛŒ SVM Ø®Ø·ÛŒ
            # (Ù…Ù†Ø·Ù‚ Ø§Ø³ØªØ®Ø±Ø§Ø¬ coef_ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ø§Ø³ Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯)
             coef_matrix = classifier.coef_
             all_features = []
             for i, class_label in enumerate(LABELS):
                class_name = CLASS_NAMES.get(class_label, f'Class {class_label}')
                coefs = coef_matrix[i]
                feature_data = list(zip(feature_names, coefs))
                feature_data.sort(key=lambda x: abs(x[1]), reverse=True)
                top_features_class = feature_data[:10]
                for feature, weight in top_features_class:
                    all_features.append({
                        'Class': class_name,
                        'Feature': feature,
                        'Weight': weight,
                        'Model Type': 'Linear (Coefficient)'
                    })
             key_words_df = pd.DataFrame(all_features)
        else:
            key_words_df = pd.DataFrame({
                'Feature': ['N/A (Classifier lacks feature_importances_ or coef_)'],
                'Weight': ['Key word analysis not applicable for this classifier type.']
            })

except KeyError as e:
    key_words_df = pd.DataFrame({
        'Feature': [f'Critical Error in Pipeline: {e}'],
        'Weight': ['Please check the step names in Selul 2.']
    })
     
print("âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ§Ú˜Ú¯Ø§Ù† Ú©Ù„ÛŒØ¯ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")


# --- Ø¯: Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ú©Ø³Ù„ ---
output_file = f'{MODEL_NAME}_Evaluation_Reports.xlsx'

with pd.ExcelWriter(output_file) as writer:
    df_overall.to_excel(writer, sheet_name='1_Overall_Metrics', index=False)
    df_class_metrics.to_excel(writer, sheet_name='2_Class_Metrics', index=False)
    key_words_df.to_excel(writer, sheet_name='3_Key_Words_Analysis', index=False)

files.download(output_file)
print(f"\nâœ… Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø¢Ù…Ø§Ø±ÛŒ Ø¬Ø§Ù…Ø¹ Ùˆ ØªØ­Ù„ÛŒÙ„ ÙˆØ§Ú˜Ú¯Ø§Ù† Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± {output_file} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")
print("Ø²Ù…Ø§Ù† Ú©Ù„ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ù„ÙˆÙ„ Û³ (Ú¯Ø²Ø§Ø±Ø´â€ŒØ¯Ù‡ÛŒ Ø¢Ù…Ø§Ø±ÛŒ):")
# =================================================================
# Ø³Ù„ÙˆÙ„ Û´: ØªØ±Ø³ÛŒÙ… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø¨ØµØ±ÛŒ Ø¬Ø§Ù…Ø¹ (Ù†Ø³Ø®Ù‡ Ù†Ù‡Ø§ÛŒÛŒ)
# =================================================================
%%time

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¹Ù…ÙˆÙ…ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ ---
plt.style.use('seaborn-v0_8-whitegrid')
CLASS_LABELS_EN = list(CLASS_NAMES.values())
COLORS = ['#1f77b4', '#ff7f0e', '#2ca02c'] 
# AUC OVR Ú©Ù‡ Ø¯Ø± Ø³Ù„ÙˆÙ„ Û³ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù‡ Ø§Ø³ØªØŒ Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
auc_roc_ovr_plot = auc_roc_ovr if isinstance(auc_roc_ovr, float) else np.nan

# Û±. Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡â€ŒØ§ÛŒ (Metrics Bar Chart)
plt.figure(figsize=(14, 7))
metrics_to_plot = ['Precision', 'Recall (Sensitivity)', 'F1-Score', 'Specificity', 'NPV (Negative Predictive Value)'] 
df_plot = df_class_metrics[df_class_metrics['Class'] != 'Macro Average'].reset_index(drop=True)
macro_avg_row = df_class_metrics[df_class_metrics['Class'] == 'Macro Average']
width = 0.15 

x = np.arange(len(metrics_to_plot))
# ØªØ±Ø³ÛŒÙ… Ù…ÛŒÙ„Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ø§Ø³
for i, class_name in enumerate(df_plot['Class']):
    plt.bar(x + i * width, df_plot.iloc[i][metrics_to_plot], width=width, label=class_name, color=COLORS[i])

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ø§Ú©Ø±Ùˆ (Macro Average) Ø¨Ù‡ ØµÙˆØ±Øª Ù†Ù‚Ø·Ù‡
for i, metric in enumerate(metrics_to_plot):
    plt.plot(x[i] + width * (len(LABELS) - 1) / 2, 
             macro_avg_row[metric].iloc[0], 
             'o', color='black', markersize=8, zorder=10, 
             label='Macro Avg' if i == 0 else "")

plt.xticks(x + width * (len(LABELS) - 1) / 2, metrics_to_plot, rotation=15)
plt.ylabel('Score Value', fontsize=12)
plt.title(f'Comparative Metrics per Class and Macro Average ({MODEL_NAME})', fontsize=14)
plt.legend(loc='lower right')
plt.tight_layout()
plt.show()


# Û². Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ (Confusion Matrix)
cm = confusion_matrix(y_test, y_pred, labels=LABELS)
cm_df = pd.DataFrame(cm, index=CLASS_LABELS_EN, columns=CLASS_LABELS_EN)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', linewidths=.5, linecolor='black', 
            annot_kws={"size": 14})
plt.title('Confusion Matrix (Test Data)', fontsize=16)
plt.ylabel('True Label', fontsize=14)
plt.xlabel('Predicted Label', fontsize=14)
plt.show()

# Û³. Ù†Ù…ÙˆØ¯Ø§Ø± ROC (Receiver Operating Characteristic)
plt.figure(figsize=(10, 7))
auc_scores = []

# Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ ØªØ±Ø³ÛŒÙ… ROC Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ø§Ø³ (One-vs-Rest)
for i in range(len(LABELS)):
    try:
        fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])
        auc_score = df_class_metrics.iloc[i]['AUC (OVR)'] 
        plt.plot(fpr, tpr, color=COLORS[i], label=f'{CLASS_LABELS_EN[i]} (AUC = {auc_score:.2f})')
    except Exception as e:
        print(f"âš ï¸ Ø§Ø®Ø·Ø§Ø±: Ø®Ø·Ø§ÛŒÛŒ Ø¯Ø± ØªØ±Ø³ÛŒÙ… ROC Ú©Ù„Ø§Ø³ {CLASS_LABELS_EN[i]} Ø±Ø® Ø¯Ø§Ø¯: {e}")

# ØªØ±Ø³ÛŒÙ… Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…Ø§Ú©Ø±Ùˆ (ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±Øª ÙˆØ¬ÙˆØ¯)
if not np.isnan(auc_roc_ovr_plot):
    mean_fpr = np.linspace(0.0, 1.0, 100) 
    # Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†â€ŒÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ù†Ø­Ù†ÛŒâ€ŒÙ‡Ø§ÛŒ ROC Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ø±ÙˆÙ†â€ŒÛŒØ§Ø¨ÛŒ
    mean_tpr = np.mean([np.interp(mean_fpr, *roc_curve(y_test_binarized[:, i], y_prob[:, i])[:2]) for i in range(len(LABELS))], axis=0)
    mean_tpr[0] = 0.0
    plt.plot(mean_fpr, mean_tpr, color='black', linestyle='--', label=f'Macro Average (AUC = {auc_roc_ovr_plot:.2f})', linewidth=2)

plt.plot([0, 1], [0, 1], 'r--', label='Random Classifier')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('ROC Curve per Class (One-vs-Rest Strategy)', fontsize=16)
plt.legend(loc="lower right")
plt.show()


# Û´. Ù†Ù…ÙˆØ¯Ø§Ø± Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† (Calibration Curve)
plt.figure(figsize=(10, 7))
plt.plot([0, 1], [0, 1], "r--", label="Perfectly Calibrated")
brier_scores = []

for i in range(len(LABELS)):
    y_true_class = (y_test == LABELS[i])
    y_prob_class = y_prob[:, i]
    
    brier = brier_score_loss(y_true_class, y_prob_class)
    brier_scores.append(brier)
    
    fraction_of_positives, mean_predicted_value = calibration_curve(
        y_true_class, y_prob_class, n_bins=10
    )
    
    plt.plot(mean_predicted_value, fraction_of_positives, "s-", 
             label=f'{CLASS_LABELS_EN[i]} (Brier: {brier:.2f})', color=COLORS[i])

mean_brier = np.mean(brier_scores)
plt.text(0.1, 0.8, f'Mean Brier Score: {mean_brier:.2f}', fontsize=12, color='black', transform=plt.gca().transAxes)
plt.text(0.1, 0.75, f'Overall Log Loss: {logloss:.4f}', fontsize=12, color='black', transform=plt.gca().transAxes)


plt.ylabel("Fraction of Positives", fontsize=12)
plt.xlabel("Mean Predicted Probability", fontsize=12)
plt.title("Calibration Curve (Predicted vs. True Probability)", fontsize=16)
plt.legend(loc="lower right")
plt.show()

print("\nâœ… ØªÙ…Ø§Ù…ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ ØªÙˆÙ„ÛŒØ¯ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯.")
print("Ø²Ù…Ø§Ù† Ú©Ù„ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ù„ÙˆÙ„ Û´ (ØªØ±Ø³ÛŒÙ… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§):")

print("\nØ²Ù…Ø§Ù† Ú©Ù„ Ø§Ø¬Ø±Ø§ÛŒ Ø³Ù„ÙˆÙ„ Û± (Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡):")
