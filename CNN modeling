# Ù†ØµØ¨ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² (TensorFlow, Keras, Parsivar)
!pip install tensorflow parsivar scikit-learn numpy pandas openpyxl

# Ø±ÛŒØ³ØªØ§Ø±Øª Ú©Ø±Ø¯Ù† Ø±Ø§Ù†â€ŒØªØ§ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø§Ø¹Ù…Ø§Ù„ Ù†ØµØ¨â€ŒÙ‡Ø§ (Ø§Ø®ØªÛŒØ§Ø±ÛŒØŒ Ø§Ù…Ø§ ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
# import os
# os.kill(os.getpid(), 9)

import pandas as pd
import numpy as np
import re
import io
import matplotlib.pyplot as plt
import seaborn as sns
import math

from google.colab import files
from parsivar import Normalizer, Tokenizer # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Parsivar
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, confusion_matrix, f1_score, matthews_corrcoef, 
    cohen_kappa_score, mean_absolute_error, recall_score, roc_auc_score, roc_curve
)

# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø¹Ù…ÛŒÙ‚
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout
from tensorflow.keras.preprocessing.text import Tokenizer as KerasTokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.utils import to_categorical

print("âœ… Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù†ØµØ¨ Ùˆ ÙˆØ§Ø±Ø¯ Ø´Ø¯Ù†Ø¯.")
# --- Ø§Ù„Ù: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ (ÙØ±Ø¶ Ø¨Ø± Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ù„ÛŒØ¨Ù„â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù‡ Ø§Ø³Øª) ---
print("Ù„Ø·ÙØ§ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ù„ÛŒØ¨Ù„â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø´Ø¯Ù‡ Ø±Ø§ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ù†ÛŒØ¯ (Ø§Ú¯Ø± Ù‚Ø¨Ù„Ø§Ù‹ Ø¢Ù¾Ù„ÙˆØ¯ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª):")
uploaded = files.upload()
file_name = next(iter(uploaded))

df = pd.read_excel(io.BytesIO(uploaded[file_name]))
df.columns = ['text', 'label'] 

# --- Ø¨: Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ (Ù‡Ù…Ø§Ù† ØªØ§Ø¨Ø¹ Ù‚Ø¨Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Parsivar) ---
normalizer = Normalizer()
tokenizer = Tokenizer()
stop_words = set([
    "Ø§Ø²", "Ø¨Ù‡", "Ø¨Ø§", "Ø¯Ø±", "Ø¨Ø±", "Ø¨Ø±Ø§ÛŒ", "Ú©Ù‡", "Ùˆ", "ÛŒØ§", "ÛŒÚ©", "Ø§ÛŒÙ†", "Ø¢Ù†",
    "Ù‡Ø§", "Ø§ÛŒ", "Ø±Ø§", "Ù‡Ù…", "Ø¨ÙˆØ¯", "Ø§Ø³Øª", "Ø¨Ø§Ø´Ø¯", "Ø´Ø¯", "Ù…ÛŒ", "Ù‡Ù…ÛŒÙ†", "Ú†Ù†ÛŒÙ†",
    "Ø§Ù…Ø§", "Ø§Ú¯Ø±", "Ú†ÙˆÙ†", "ØªØ§", "Ù…Ø§", "Ù…Ù†", "ØªÙˆ", "Ø§Ùˆ", "Ø´Ù…Ø§", "Ø§ÛŒØ´Ø§Ù†"
])

def preprocess_text(text):
    if pd.isna(text) or not text:
        return ""
    text = normalizer.normalize(str(text))
    text = re.sub(r'http\S+|www\S+|#\w+|@\w+', '', text, flags=re.MULTILINE)
    text = re.sub(r'[^\u0600-\u06FF\s]', '', text) 
    text = re.sub(r'\s+', ' ', text).strip()
    
    tokens = tokenizer.tokenize_words(text)
    filtered_tokens = [token for token in tokens if token not in stop_words and len(token) > 1]
    
    return ' '.join(filtered_tokens)

df['cleaned_text'] = df['text'].apply(preprocess_text)
print("âœ… Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø¨Ø§ Parsivar Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯.")

# --- Ø¬: ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø²ÛŒ Ùˆ Padding Ø¨Ø±Ø§ÛŒ CNN ---
MAX_WORDS = 5000     # Ø­Ø¯Ø§Ú©Ø«Ø± ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ø¯Ø± ÙˆØ§Ú˜Ù‡â€ŒÙ†Ø§Ù…Ù‡
MAX_SEQ_LENGTH = 100 # Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„ Ù‡Ø± ØªÙˆØ¦ÛŒØª (Ø¨Ø±Ø§ÛŒ Padding)
EMBEDDING_DIM = 100  # Ø§Ø¨Ø¹Ø§Ø¯ ÙØ¶Ø§ÛŒ ØªØ¹Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ (Ù…Ø§Ù†Ù†Ø¯ Word2Vec/FastText)

# Ø§ÛŒØ¬Ø§Ø¯ ØªÙˆÚ©Ù†â€ŒØ³Ø§Ø² Keras
keras_tokenizer = KerasTokenizer(num_words=MAX_WORDS, oov_token="<unk>")
keras_tokenizer.fit_on_texts(df['cleaned_text'])

# ØªØ¨Ø¯ÛŒÙ„ Ù…ØªÙ† Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ
sequences = keras_tokenizer.texts_to_sequences(df['cleaned_text'])

# ÛŒÚ©Ø³Ø§Ù†â€ŒØ³Ø§Ø²ÛŒ Ø·ÙˆÙ„ Ø¯Ù†Ø¨Ø§Ù„Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ Padding
X = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH)
y = df['label'].values

# ØªØ¨Ø¯ÛŒÙ„ Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ Ø¨Ù‡ ÙØ±Ù…Øª One-Hot Encoding (Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Keras Ú†Ù†Ø¯ Ú©Ù„Ø§Ø³Ù‡)
num_classes = len(np.unique(y))
y_one_hot = to_categorical(y, num_classes=num_classes)

print(f"âœ… Ø§Ø¨Ø¹Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ (X): {X.shape}")
print(f"âœ… Ø§Ø¨Ø¹Ø§Ø¯ Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ (y_one_hot): {y_one_hot.shape}")
# --- Ø§Ù„Ù: ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ (Û¶Û°:Û³Û°:Û±Û°) ---
X_train, X_temp, y_train, y_temp = train_test_split(
    X, y_one_hot, test_size=0.4, random_state=42, stratify=y
)
validation_ratio_from_temp = 0.25 
X_test, X_val, y_test, y_val = train_test_split(
    X_temp, y_temp, 
    test_size=validation_ratio_from_temp, 
    random_state=42, 
    # ØªÙˆØ¬Ù‡: Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ y_temp (One-Hot) Ø±Ø§ Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† stratify Ú©Ø±Ø¯.
    # Ø¨Ø§ÛŒØ¯ Ø§Ø² Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ y_temp_labels Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´ÙˆØ¯
    stratify=np.argmax(y_temp, axis=1) 
)

print(f"âœ… ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: Train: {len(X_train)}, Test: {len(X_test)}, Validation: {len(X_val)}")

# --- Ø¨: Ø³Ø§Ø®Øª Ù…Ø¯Ù„ CNN ---
model = Sequential()

# Û±. Ù„Ø§ÛŒÙ‡ ØªØ¹Ø¨ÛŒÙ‡â€ŒØ³Ø§Ø²ÛŒ (Embedding Layer): ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ø±Ø¯Ø§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ù…Ù‡
model.add(Embedding(input_dim=MAX_WORDS, 
                    output_dim=EMBEDDING_DIM, 
                    input_length=MAX_SEQ_LENGTH, 
                    name='embedding_layer'))

# Û². Ù„Ø§ÛŒÙ‡ Ù¾ÛŒÚ†Ø´ÛŒ (Convolutional Layer): ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ (n-grams)
model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))

# Û³. Ù„Ø§ÛŒÙ‡ Pooling: Ú©Ø§Ù‡Ø´ Ø§Ø¨Ø¹Ø§Ø¯ Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒ
model.add(GlobalMaxPooling1D())

# Û´. Ù„Ø§ÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Dense (ÙØ´Ø±Ø¯Ù‡): ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ù†Ù‡Ø§ÛŒÛŒ
# Dropout Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Overfitting Ø¨Ø³ÛŒØ§Ø± Ø­ÛŒØ§ØªÛŒ Ø§Ø³Øª.
model.add(Dropout(0.5)) 
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax')) # Softmax Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡

# Ú©Ø§Ù…Ù¾Ø§ÛŒÙ„ Ù…Ø¯Ù„
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Ù†Ù…Ø§ÛŒØ´ Ø³Ø§Ø®ØªØ§Ø± Ù…Ø¯Ù„
model.summary()
print("\nğŸš€ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ CNN Ø¢ØºØ§Ø² Ø´Ø¯...")

# --- Ø¬: Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ ---
# Early Stopping Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ø§Ø² Overfitting Ø¨Ø± Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Validation
early_stopping = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', # Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Loss Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
    patience=3,         # ØªØ¹Ø¯Ø§Ø¯ Ø¯ÙˆØ±Ù‡Ø§ÛŒ ØªØ­Ù…Ù„ (Ø§Ú¯Ø± Ø¯Ø± 3 Ø¯ÙˆØ± Ø¨Ù‡Ø¨ÙˆØ¯ Ù†ÛŒØ§ÙØªØŒ Ù…ØªÙˆÙ‚Ù Ø´ÙˆØ¯)
    restore_best_weights=True
)

history = model.fit(
    X_train, y_train,
    epochs=20, # ØªØ¹Ø¯Ø§Ø¯ Ø¯ÙˆØ±Ù‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±
    batch_size=32,
    validation_data=(X_val, y_val), # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¬Ù…ÙˆØ¹Ù‡ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
    callbacks=[early_stopping],
    verbose=1
)

print("âœ… Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ CNN Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯.")

# --- Ø¯: Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª ---
y_prob_cnn = model.predict(X_test)
# ØªØ¨Ø¯ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ One-Hot Ø¨Ù‡ Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ (0ØŒ 1ØŒ 2)
y_pred_cnn = np.argmax(y_prob_cnn, axis=1) 
y_test_labels = np.argmax(y_test, axis=1)
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import (
    accuracy_score, confusion_matrix, f1_score, matthews_corrcoef, 
    cohen_kappa_score, mean_absolute_error, recall_score, roc_auc_score, roc_curve
)

# --- ØªØ¹Ø±ÛŒÙ Ù†Ø§Ù… Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§ ---
LABELS = [0, 1, 2]
CLASS_NAMES = {
    0: 'Non-related', 
    1: 'Indirect Suicide Signs', 
    2: 'Direct Suicide Signs'
}

# --- Ø§Ù„Ù: Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø§Ú©Ø³Ù„ ---

# Û±. Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
accuracy = accuracy_score(y_test_labels, y_pred_cnn)
kappa = cohen_kappa_score(y_test_labels, y_pred_cnn)
mcc = matthews_corrcoef(y_test_labels, y_pred_cnn)
f1_macro = f1_score(y_test_labels, y_pred_cnn, average='macro')
f1_weighted = f1_score(y_test_labels, y_pred_cnn, average='weighted')
# MAE Ùˆ RMSE Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ù†Ø§Ø³Ø¨ Ù†ÛŒØ³ØªÙ†Ø¯ØŒ Ø§Ù…Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯.
mae = mean_absolute_error(y_test_labels, y_pred_cnn)
rmse = math.sqrt(np.mean((y_test_labels - y_pred_cnn)**2)) 
recall_macro = recall_score(y_test_labels, y_pred_cnn, average='macro')

# Û². AUC-ROC (OVR)
try:
    auc_roc_ovr = roc_auc_score(y_test, y_prob_cnn, multi_class='ovr')
except ValueError:
    auc_roc_ovr = "N/A"

# Û³. Specificity (Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ø§Ø³)
tn_rate = {}
for i in LABELS:
    tn, fp, fn, tp = confusion_matrix(y_test_labels == i, y_pred_cnn == i).ravel()
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0 
    tn_rate[i] = specificity

# Û´. Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø§Ú©Ø³Ù„
results = {
    'Metric': [
        'Accuracy', "Cohen's Kappa", 'MCC', 'F1-score (Macro)', 
        'F1-score (Weighted)', 'MAE', 'RMSE', 'Macro Average Recall (Sensitivity)', 
        'AUC-ROC (OVR)'
    ],
    'Value': [
        accuracy, kappa, mcc, f1_macro, f1_weighted, mae, rmse, 
        recall_macro, auc_roc_ovr
    ]
}
results_df = pd.DataFrame(results)

for label, name in CLASS_NAMES.items():
    results_df = pd.concat([results_df, pd.DataFrame({
        'Metric': [f'Specificity ({name})'],
        'Value': [tn_rate[label]]
    })], ignore_index=True)

output_results_file = 'CNN_Evaluation_Metrics.xlsx'
results_df.to_excel(output_results_file, index=False)
files.download(output_results_file)
print("âœ… Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù…Ø­Ø§Ø³Ø¨Ù‡ Ùˆ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù†Ø¯.")
print("\n--- Ø®Ù„Ø§ØµÙ‡â€ŒØ§ÛŒ Ø§Ø² Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ ---")
print(results_df.head(10).to_string(index=False))

# --- Ø¨: ØªØ±Ø³ÛŒÙ… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ ---

# Û±. Confusion Matrix
cm = confusion_matrix(y_test_labels, y_pred_cnn, labels=LABELS)
cm_df = pd.DataFrame(cm, index=CLASS_NAMES.values(), columns=CLASS_NAMES.values())

plt.figure(figsize=(8, 6))
sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', linewidths=.5, linecolor='black')
plt.title('Confusion Matrix', fontsize=16)
plt.ylabel('True Label (Actual)', fontsize=14)
plt.xlabel('Predicted Label', fontsize=14)
plt.show()


# Û². AUC-ROC Curve per Class
plt.figure(figsize=(10, 7))
lb = LabelBinarizer()
y_test_binarized = lb.fit_transform(y_test_labels) # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ ØªØ³Øª

for i in range(len(LABELS)):
    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_prob_cnn[:, i])
    auc_score = roc_auc_score(y_test_binarized[:, i], y_prob_cnn[:, i])
    
    plt.plot(fpr, tpr, 
             label=f"Class {LABELS[i]} ({CLASS_NAMES[LABELS[i]]}) AUC = {auc_score:.2f}")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)
plt.ylabel('True Positive Rate (Recall/Sensitivity)', fontsize=12)
plt.title('AUC-ROC Curve per Class (One-vs-Rest Strategy)', fontsize=16)
plt.legend(loc="lower right")
plt.grid(True)
plt.show()


# --- Ø¬: Ù†Ù…ÙˆØ¯Ø§Ø± Loss Ùˆ Accuracy Ø¢Ù…ÙˆØ²Ø´ ---
plt.figure(figsize=(12, 5))

# Loss
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# Accuracy
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy Over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()


print("\nâœ… ØªÙ…Ø§Ù…ÛŒ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³ØªÛŒ ØªÙˆÙ„ÛŒØ¯ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù†Ø¯.")
