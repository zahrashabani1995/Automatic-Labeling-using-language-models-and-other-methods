# نصب کتابخانه‌های مورد نیاز
!pip install transformers parsivar scikit-learn numpy pandas openpyxl torch

import pandas as pd
import numpy as np
import re
import io
import matplotlib.pyplot as plt
import seaborn as sns
import math
import torch

from google.colab import files
from parsivar import Normalizer, Tokenizer 
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC 
from sklearn.metrics import (
    accuracy_score, confusion_matrix, f1_score, matthews_corrcoef, 
    cohen_kappa_score, mean_absolute_error, recall_score, roc_auc_score, roc_curve
)
from sklearn.preprocessing import LabelBinarizer

# ابزارهای XLM-RoBERTa
from transformers import AutoTokenizer, AutoModel

# --- بارگذاری فایل و پیش‌پردازش ---

print("لطفا فایل اکسل لیبل‌گذاری شده را آپلود کنید:")
uploaded = files.upload()
file_name = next(iter(uploaded))

df = pd.read_excel(io.BytesIO(uploaded[file_name]))
df.columns = ['text', 'label'] 
print(f"✅ فایل با {len(df)} سطر با موفقیت خوانده شد.")

# --- پیش‌پردازش (آماده‌سازی Parsivar) ---
normalizer = Normalizer()
tokenizer = Tokenizer()
stop_words = set([
    "از", "به", "با", "در", "بر", "برای", "که", "و", "یا", "یک", "این", "آن",
    "ها", "ای", "را", "هم", "بود", "است", "باشد", "شد", "می", "همین", "چنین",
    "اما", "اگر", "چون", "تا", "ما", "من", "تو", "او", "شما", "ایشان"
])

def preprocess_text(text):
    """تابع جامع پیش‌پردازش متن فارسی با Parsivar"""
    if pd.isna(text) or not text:
        return ""
    
    text = normalizer.normalize(str(text))
    text = re.sub(r'http\S+|www\S+|#\w+|@\w+', '', text, flags=re.MULTILINE)
    text = re.sub(r'[^\u0600-\u06FF\s]', '', text) 
    text = re.sub(r'\s+', ' ', text).strip()
    
    tokens = tokenizer.tokenize_words(text)
    filtered_tokens = [token for token in tokens if token not in stop_words and len(token) > 1]
    
    return ' '.join(filtered_tokens)

# اعمال پیش‌پردازش
# --- الف: استخراج بردارها با XLM-RoBERTa ---
texts = df['cleaned_text'].tolist()
y = df['label'].values

# بارگذاری توکن‌ساز و مدل XLM-RoBERTa
print("🚀 بارگذاری مدل XLM-RoBERTa آغاز شد...")
# **مدل عمومی و پایدار XLM-RoBERTa**
model_name = "xlm-roberta-base" 
bert_tokenizer = AutoTokenizer.from_pretrained(model_name)
bert_model = AutoModel.from_pretrained(model_name)
print(f"✅ مدل XLM-RoBERTa ({model_name}) با موفقیت بارگذاری شد.")

# انتقال مدل به GPU در صورت وجود
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
bert_model = bert_model.to(device)

def get_xlmr_embeddings(texts):
    """تولید بردار از CLS Token برای هر جمله با XLM-RoBERTa"""
    X_embeddings = []
    chunk_size = 100 # برای مدیریت حافظه
    
    with torch.no_grad(): # خاموش کردن گرادیان‌ها
        for i in range(0, len(texts), chunk_size):
            chunk_texts = texts[i:i + chunk_size]
            
            # توکن‌سازی متن
            encoded_input = bert_tokenizer(
                chunk_texts, 
                padding=True, 
                truncation=True, 
                max_length=128, 
                return_tensors='pt'
            )
            encoded_input = {k: v.to(device) for k, v in encoded_input.items()}
            
            # اجرای مدل
            output = bert_model(**encoded_input)
            
            # استخراج بردار [CLS] (اولین توکن)
            cls_embeddings = output.last_hidden_state[:, 0, :].cpu().numpy()
            
            X_embeddings.extend(cls_embeddings)
            
    return np.array(X_embeddings)

print("🚀 تولید بردارهای معنایی برای داده‌ها... (این فرآیند زمان‌بر است)")
X_xlmr = get_xlmr_embeddings(texts) 

print(f"✅ تولید بردارها با موفقیت انجام شد. ابعاد ویژگی (X_xlmr): {X_xlmr.shape}")

# --- ب: تقسیم داده‌ها (۶۰:۳۰:۱۰) ---
X_train, X_temp, y_train, y_temp = train_test_split(
    X_xlmr, y, test_size=0.4, random_state=42, stratify=y
)
validation_ratio_from_temp = 0.25 
X_test, X_val, y_test, y_val = train_test_split(
    X_temp, y_temp, 
    test_size=validation_ratio_from_temp, 
    random_state=42, 
    stratify=y_temp
)

print(f"✅ تقسیم داده‌ها بر اساس نسبت ۶۰:۳۰:۱۰ انجام شد: Train: {len(X_train)}, Test: {len(X_test)}, Validation: {len(X_val)}")

# --- ج: آموزش طبقه‌بند SVM ---
svm_classifier = SVC(
    kernel='linear', 
    C=1.0, 
    random_state=42, 
    probability=True
)

print("\n🚀 آموزش طبقه‌بند SVM با بردارهای XLM-RoBERTa آغاز شد...")
svm_classifier.fit(X_train, y_train)
print("✅ آموزش طبقه‌بند با موفقیت به پایان رسید.")

# --- د: پیش‌بینی روی داده‌های تست ---
y_pred = svm_classifier.predict(X_test)
y_prob = svm_classifier.predict_proba(X_test)
df['cleaned_text'] = df['text'].apply(preprocess_text)
# --- تعریف نام دسته‌ها ---
LABELS = [0, 1, 2]
CLASS_NAMES = {
    0: 'Non-related', 
    1: 'Indirect Suicide Signs', 
    2: 'Direct Suicide Signs'
}

# --- الف: محاسبه معیارها و ذخیره در اکسل ---

# ۱. معیارهای اصلی
accuracy = accuracy_score(y_test, y_pred)
kappa = cohen_kappa_score(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
f1_macro = f1_score(y_test, y_pred, average='macro')
f1_weighted = f1_score(y_test, y_pred, average='weighted')
mae = mean_absolute_error(y_test, y_pred)
rmse = math.sqrt(np.mean((y_test - y_pred)**2)) 
recall_macro = recall_score(y_test, y_pred, average='macro')

# ۲. AUC-ROC (OVR)
lb = LabelBinarizer()
y_test_binarized = lb.fit_transform(y_test)
try:
    auc_roc_ovr = roc_auc_score(y_test_binarized, y_prob, multi_class='ovr')
except ValueError:
    auc_roc_ovr = "N/A"

# ۳. Specificity (برای هر کلاس)
tn_rate = {}
for i in LABELS:
    tn, fp, fn, tp = confusion_matrix(y_test == i, y_pred == i).ravel()
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0 
    tn_rate[i] = specificity

# ۴. جمع‌آوری و ذخیره در اکسل
results = {
    'Metric': [
        'Accuracy', "Cohen's Kappa", 'MCC', 'F1-score (Macro)', 
        'F1-score (Weighted)', 'MAE', 'RMSE', 'Macro Average Recall (Sensitivity)', 
        'AUC-ROC (OVR)'
    ],
    'Value': [
        accuracy, kappa, mcc, f1_macro, f1_weighted, mae, rmse, 
        recall_macro, auc_roc_ovr
    ]
}
results_df = pd.DataFrame(results)

for label, name in CLASS_NAMES.items():
    results_df = pd.concat([results_df, pd.DataFrame({
        'Metric': [f'Specificity ({name})'],
        'Value': [tn_rate[label]]
    })], ignore_index=True)

output_results_file = 'XLM_ROBERTA_SVM_Evaluation_Metrics.xlsx'
results_df.to_excel(output_results_file, index=False)
files.download(output_results_file)
print("✅ معیارهای ارزیابی با موفقیت محاسبه و در فایل اکسل ذخیره شدند.")

# --- ب: ترسیم نمودارها ---

# ۱. Confusion Matrix
cm = confusion_matrix(y_test, y_pred, labels=LABELS)
cm_df = pd.DataFrame(cm, index=CLASS_NAMES.values(), columns=CLASS_NAMES.values())

plt.figure(figsize=(8, 6))
sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', linewidths=.5, linecolor='black')
plt.title('Confusion Matrix (XLM-RoBERTa+SVM)', fontsize=16)
plt.ylabel('True Label (Actual)', fontsize=14)
plt.xlabel('Predicted Label', fontsize=14)
plt.show()


# ۲. AUC-ROC Curve per Class
plt.figure(figsize=(10, 7))

for i in range(len(LABELS)):
    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])
    auc_score = roc_auc_score(y_test_binarized[:, i], y_prob[:, i])
    
    plt.plot(fpr, tpr, 
             label=f"Class {LABELS[i]} ({CLASS_NAMES[LABELS[i]]}) AUC = {auc_score:.2f}")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (1 - Specificity)', fontsize=12)
plt.ylabel('True Positive Rate (Recall/Sensitivity)', fontsize=12)
plt.title('AUC-ROC Curve per Class (One-vs-Rest Strategy)', fontsize=16)
plt.legend(loc="lower right")
plt.grid(True)
plt.show()


print("\n✅ تمامی نمودارهای درخواستی تولید و نمایش داده شدند.")
print("✅ پیش‌پردازش متن با Parsivar انجام شد.")
