# =================================================================
# سلول ۱: نصب، بارگذاری، پیش‌پردازش و ایمپورت‌های نهایی (Word2Vec)
# =================================================================
%%time

# --- نصب کتابخانه‌های مورد نیاز ---
# نصب تمام پکیج‌های مورد نیاز شامل parsivar، imbalanced-learn و gensim
!pip install pandas numpy scikit-learn parsivar matplotlib seaborn imbalanced-learn openpyxl gensim --quiet

# --- ایمپورت کتابخانه‌های مورد نیاز ---
import pandas as pd
import numpy as np
import re
import io
import time
import math
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
from parsivar import Normalizer, Tokenizer 
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score, confusion_matrix, f1_score, matthews_corrcoef, 
    cohen_kappa_score, recall_score, make_scorer, roc_auc_score, roc_curve, 
    precision_recall_fscore_support, precision_score, log_loss, mean_absolute_error,
    brier_score_loss
)
from sklearn.preprocessing import LabelBinarizer
from sklearn.pipeline import Pipeline
from sklearn.calibration import calibration_curve
from imblearn.pipeline import Pipeline as ImbPipeline 
from imblearn.over_sampling import SMOTE 
from sklearn.feature_extraction.text import TfidfVectorizer 
import gensim.models

# --- توابع پیش‌پردازش فارسی ---
normalizer = Normalizer()
tokenizer = Tokenizer()

def preprocess_text(text):
    """اعمال نرمال‌سازی و توکن‌سازی اولیه روی متن فارسی."""
    if pd.isna(text):
        return ""
    # نرمال‌سازی فارسی (اصلاح نیم‌فاصله، ک‌ها، ی‌ها و...)
    text = normalizer.normalize(text)
    # حذف اعداد
    text = re.sub(r'[۰-۹]', '', text) 
    text = re.sub(r'[0-9]', '', text) 
    # حذف علائم نگارشی (به جز کاراکترهای مجاز)
    text = re.sub(r'[^\w\s]', '', text) 
    # حذف زیرخط‌ها
    text = re.sub(r'_', '', text) 
    # توکن‌سازی و حذف توکن‌های خالی
    tokens = [token for token in tokenizer.tokenize_words(text) if token.strip()]
    return " ".join(tokens)


# --- بارگذاری فایل و اعمال پیش‌پردازش ---
print("\n🔄 لطفا فایل اکسل لیبل‌گذاری شده (شامل ستون‌های 'text' و 'label') را آپلود کنید.")
try:
    # بخش آپلود
    uploaded = files.upload()
    file_name = next(iter(uploaded))
    df = pd.read_excel(io.BytesIO(uploaded[file_name]))
    
    # اطمینان از نام ستون‌ها و تبدیل به حروف کوچک
    df.columns = df.columns.str.lower()
    if 'text' not in df.columns or 'label' not in df.columns:
         raise ValueError("فایل اکسل باید شامل ستون‌های 'text' و 'label' باشد (بدون حساسیت به حروف بزرگ/کوچک).")

    # حذف سطرهای دارای NaN در ستون‌های اصلی
    df.dropna(subset=['text', 'label'], inplace=True)
    
    # اعمال پیش‌پردازش
    df['cleaned_text'] = df['text'].apply(preprocess_text)
    
    # تبدیل لیبل‌ها به عدد صحیح
    y_labels = df['label'].astype(int).values 
    LABELS = np.unique(y_labels).tolist() 
    
    # 💡 تعریف نام‌های کلاس (بر اساس لیبل‌های عددی شما)
    CLASS_NAMES = {
        0: 'Non-related', 
        1: 'Indirect Suicide Signs', 
        2: 'Direct Suicide Signs'
    }
    
    # --- تقسیم داده‌ها (60% آموزش، 30% اعتبارسنجی، 10% تست) ---
    X = df['cleaned_text']
    y = y_labels

    # 1. تقسیم به Training (60%) و Temp (40%)
    X_train, X_temp, y_train, y_temp = train_test_split(
        X, y, test_size=0.4, random_state=42, stratify=y
    )

    # 2. تقسیم Temp به Validation (30%) و Test (10%)
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp
    )

    print(f"\n✅ فایل با {len(df)} سطر با موفقیت خوانده شد و پیش‌پردازش و تقسیم شد.")
    print(f"\n📊 توزیع داده‌ها:")
    print(f"آموزش (Train): {len(X_train)} ({len(X_train) / len(df) * 100:.1f}%)")
    print(f"اعتبارسنجی (Validation): {len(X_val)} ({len(X_val) / len(df) * 100:.1f}%)")
    print(f"تست (Test): {len(X_test)} ({len(X_test) / len(df) * 100:.1f}%)")

except Exception as e:
    print(f"❌ خطا در بارگذاری یا خواندن فایل: {e}")
    # اگر فایل آپلود نشود، اجرای نوت‌بوک متوقف می‌شود
    # توجه: اگر فایل قبلاً در حافظه Colab باشد، ممکن است این بخش نیاز به تغییر داشته باشد.
    raise 
# =================================================================
# سلول ۲: مدلسازی SVM با FastText و SMOTE (نسخه نهایی)
# =================================================================
%%time

MODEL_NAME = "SVM_FastText_SMOTE" 

# --- ایمپورت‌های مورد نیاز (فرض می‌شود در سلول ۱ موجودند) ---
from sklearn.base import BaseEstimator, TransformerMixin
import gensim.models.fasttext as FastTextModel 
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, f1_score
from imblearn.pipeline import Pipeline as ImbPipeline # 🚨 استفاده از ImbPipeline
from imblearn.over_sampling import SMOTE 
from sklearn.svm import SVC
import numpy as np
import time

# --- ۱. تعریف FastText Embedding (بدون تغییر نسبت به قبل) ---

class FastTextVectorizer(BaseEstimator, TransformerMixin):
    """تبدیل کننده متن به بردار میانگین کلمات با استفاده از Gensim FastText."""
    
    def __init__(self, vector_size=100, min_count=1, window=5, workers=4, min_n=3, max_n=6):
        self.vector_size = vector_size
        self.min_count = min_count
        self.window = window
        self.workers = workers
        self.min_n = min_n 
        self.max_n = max_n 
        self.fasttext_model = None

    def fit(self, X, y=None):
        tokenized_sentences = [text.split() for text in X]
        
        print(f"🚀 شروع آموزش FastText با vector_size={self.vector_size}, min_n={self.min_n}...")
        
        self.fasttext_model = FastTextModel.FastText(
            sentences=tokenized_sentences,
            vector_size=self.vector_size,
            min_count=self.min_count,
            window=self.window,
            workers=self.workers,
            min_n=self.min_n, 
            max_n=self.max_n, 
            seed=42
        )
        self.fasttext_model.train(tokenized_sentences, total_examples=len(tokenized_sentences), epochs=10)
        print("✅ آموزش FastText به پایان رسید.")
        return self

    def transform(self, X):
        tokenized_sentences = [text.split() for text in X]
        
        def get_mean_vector(tokens):
            vectors = [self.fasttext_model.wv[word] for word in tokens]
            if vectors:
                return np.mean(vectors, axis=0)
            else:
                return np.zeros(self.vector_size)

        return np.array([get_mean_vector(tokens) for tokens in tokenized_sentences])


# --- تعریف اجزای Pipeline (با SMOTE) ---
fasttext_vectorizer = FastTextVectorizer(vector_size=200) 
smote_sampler = SMOTE(random_state=42) # 👈 مرحله جدید: متعادل‌سازی
svm_classifier = SVC(random_state=42, probability=True, decision_function_shape='ovr') 

# 🚨 استفاده از ImbPipeline برای مدیریت مراحل پیش‌پردازش و متعادل‌سازی
pipeline = ImbPipeline([
    ('embedding', fasttext_vectorizer),
    ('smote', smote_sampler), # 👈 SMOTE بعد از Embedding
    ('clf', svm_classifier) 
])

# --- تنظیم هایپارامترها (Grid Search) ---
param_grid = {
    # FastText parameters
    'embedding__vector_size': [100, 200], 
    # SMOTE parameter (تعداد همسایه‌ها)
    'smote__k_neighbors': [3, 5], 
    # SVC parameters
    'clf__C': [1, 10], 
    'clf__kernel': ['linear'] 
}

f1_macro_scorer = make_scorer(f1_score, average='macro')

print("🚀 شروع Grid Search و آموزش مدل...")
grid_search_start = time.time()

# 🚨 اجرای Grid Search
grid_search = GridSearchCV(
    estimator=pipeline,
    param_grid=param_grid,
    scoring=f1_macro_scorer,
    cv=3, 
    verbose=1,
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

grid_search_end = time.time()
training_time = grid_search_end - grid_search_start

best_model = grid_search.best_estimator_
best_params = grid_search.best_params_

print(f"\n✅ آموزش با موفقیت به پایان رسید. زمان آموزش: {training_time:.2f} ثانیه")
print(f"✅ بهترین هایپارامترهای یافت شده: {best_params}")

# ۴. ارزیابی نهایی روی داده‌های Test
y_pred = best_model.predict(X_test)
y_prob = best_model.predict_proba(X_test)

print("\nزمان کل اجرای سلول ۲ (مدلسازی):")
# =================================================================
# سلول ۳: محاسبه و ذخیره گزارش‌های آماری جامع (نسخه نهایی و Word2Vec)
# =================================================================
%%time

from sklearn.metrics import log_loss, mean_absolute_error, roc_auc_score, precision_recall_fscore_support, confusion_matrix

# --- الف: محاسبه معیارهای کلی (فایل اکسل ۱) ---
accuracy = accuracy_score(y_test, y_pred)
f1_macro = f1_score(y_test, y_pred, average='macro')
recall_macro = recall_score(y_test, y_pred, average='macro')
precision_macro = precision_score(y_test, y_pred, average='macro')
kappa = cohen_kappa_score(y_test, y_pred)
mcc = matthews_corrcoef(y_test, y_pred)
logloss = log_loss(y_test, y_prob)
mae = mean_absolute_error(y_test, y_pred)

lb = LabelBinarizer()
y_test_binarized = lb.fit_transform(y_test)

# محاسبه AUC OVR و OVO
try:
    if len(LABELS) > 2:
        auc_roc_ovr = roc_auc_score(y_test_binarized, y_prob, multi_class='ovr')
        auc_roc_ovo = roc_auc_score(y_test, y_prob, multi_class='ovo')
    elif len(LABELS) == 2:
        auc_roc_ovr = roc_auc_score(y_test_binarized, y_prob[:, 1])
        auc_roc_ovo = "N/A (Binary)"
    else:
        auc_roc_ovr = "N/A"
        auc_roc_ovo = "N/A"
except Exception: 
    auc_roc_ovr = "Error"
    auc_roc_ovo = "Error"

results_overall = {
    'Model': [MODEL_NAME], 'Embedding': ['Word2Vec (Gensim)'],
    'Accuracy': [accuracy], 'F1-Macro': [f1_macro], 'Recall-Macro': [recall_macro],
    'Precision-Macro': [precision_macro], 'Kappa': [kappa], 'MCC': [mcc],
    'AUC-ROC (OVR)': [auc_roc_ovr], 'AUC-ROC (OVO)': [auc_roc_ovo],
    'Log Loss': [logloss], 'MAE': [mae],
    'Training Time (s)': [training_time]
}
df_overall = pd.DataFrame(results_overall)


# --- ب: محاسبه معیارهای تفکیک شده بر اساس کلاس (فایل اکسل ۲) ---
precision_c, recall_c, f1_c, support_c = precision_recall_fscore_support(
    y_test, y_pred, labels=LABELS, average=None
)

# محاسبه Specificity، NPV و AUC برای هر کلاس
specificity_c = []
npv_c = []
auc_c = []

for i, label in enumerate(LABELS):
    # محاسبه TN, FP, FN, TP برای هر کلاس (True vs. Not-True)
    cm_binary = confusion_matrix(y_test == label, y_pred == label, labels=[True, False])
    
    if cm_binary.size == 4:
        tn, fp, fn, tp = cm_binary.ravel()
    else:
        tn, fp, fn, tp = 0, 0, 0, 0

    # Specificity
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0 
    specificity_c.append(specificity)

    # NPV
    npv = tn / (tn + fn) if (tn + fn) > 0 else 0 
    npv_c.append(npv)
    
    # محاسبه AUC برای هر کلاس
    try:
        auc_class = roc_auc_score(y_test_binarized[:, i], y_prob[:, i])
        auc_c.append(auc_class)
    except Exception:
        auc_c.append(np.nan)


df_class_metrics = pd.DataFrame({
    'Class': [CLASS_NAMES.get(i, f'Class {i}') for i in LABELS],
    'Precision': precision_c,
    'Recall (Sensitivity)': recall_c, 
    'Specificity': specificity_c,
    'F1-Score': f1_c,
    'NPV (Negative Predictive Value)': npv_c,
    'AUC (OVR)': auc_c,
    'Support': support_c
})

# اضافه کردن میانگین‌ها به پایین جدول کلاس‌ها
df_class_metrics.loc[len(df_class_metrics)] = {
    'Class': 'Macro Average',
    'Precision': precision_macro, 
    'Recall (Sensitivity)': recall_macro, 
    'F1-Score': f1_macro, 
    'Specificity': np.mean(specificity_c), 
    'NPV (Negative Predictive Value)': np.mean(npv_c),
    'AUC (OVR)': auc_roc_ovr if isinstance(auc_roc_ovr, float) else np.nan,
    'Support': np.sum(support_c)
}


# --- ج: استخراج واژگان کلیدی (فایل اکسل ۳ - غیرقابل اجرا برای Word2Vec) ---
key_words_df = pd.DataFrame({
    'Feature': ['N/A (Word2Vec Embeddings are dense vectors)'],
    'Weight': ['Key word analysis not applicable for this embedding type.']
}) 
print("⚠️ اخطار: تحلیل واژگان کلیدی برای Embeddingهای Word2Vec معنی‌دار نیست و حذف شد.")


# --- د: ذخیره‌سازی نهایی در فایل‌های اکسل ---
output_file = f'{MODEL_NAME}_Evaluation_Reports.xlsx'
from google.colab import files # ایمپورت مجدد در صورت نیاز

with pd.ExcelWriter(output_file) as writer:
    df_overall.to_excel(writer, sheet_name='1_Overall_Metrics', index=False)
    df_class_metrics.to_excel(writer, sheet_name='2_Class_Metrics', index=False)
    key_words_df.to_excel(writer, sheet_name='3_Key_Words_Analysis', index=False)

files.download(output_file)
print(f"\n✅ گزارش‌های آماری جامع و تحلیل واژگان با موفقیت در {output_file} ذخیره شدند.")
print("زمان کل اجرای سلول ۳ (گزارش‌دهی آماری):")
# =================================================================
# سلول ۴: ترسیم نمودارهای بصری جامع (نسخه نهایی)
# =================================================================
%%time

# --- تنظیمات عمومی نمودارها ---
plt.style.use('seaborn-v0_8-whitegrid')
CLASS_LABELS_EN = list(CLASS_NAMES.values())
COLORS = ['#1f77b4', '#ff7f0e', '#2ca02c'] 
# AUC OVR که در سلول ۳ محاسبه شده است، را برای نمودار استفاده می‌کنیم
auc_roc_ovr_plot = auc_roc_ovr if isinstance(auc_roc_ovr, float) else np.nan

# ۱. نمودار میله‌ای مقایسه‌ای (Metrics Bar Chart)
plt.figure(figsize=(14, 7))
metrics_to_plot = ['Precision', 'Recall (Sensitivity)', 'F1-Score', 'Specificity', 'NPV (Negative Predictive Value)'] 
df_plot = df_class_metrics[df_class_metrics['Class'] != 'Macro Average'].reset_index(drop=True)
macro_avg_row = df_class_metrics[df_class_metrics['Class'] == 'Macro Average']
width = 0.15 

x = np.arange(len(metrics_to_plot))
# ترسیم میله‌ها برای هر کلاس
for i, class_name in enumerate(df_plot['Class']):
    plt.bar(x + i * width, df_plot.iloc[i][metrics_to_plot], width=width, label=class_name, color=COLORS[i])

# اضافه کردن میانگین ماکرو (Macro Average) به صورت نقطه
for i, metric in enumerate(metrics_to_plot):
    plt.plot(x[i] + width * (len(LABELS) - 1) / 2, 
             macro_avg_row[metric].iloc[0], 
             'o', color='black', markersize=8, zorder=10, 
             label='Macro Avg' if i == 0 else "")

plt.xticks(x + width * (len(LABELS) - 1) / 2, metrics_to_plot, rotation=15)
plt.ylabel('Score Value', fontsize=12)
plt.title(f'Comparative Metrics per Class and Macro Average ({MODEL_NAME})', fontsize=14)
plt.legend(loc='lower right')
plt.tight_layout()
plt.show()


# ۲. ماتریس درهم‌ریختگی (Confusion Matrix)
cm = confusion_matrix(y_test, y_pred, labels=LABELS)
cm_df = pd.DataFrame(cm, index=CLASS_LABELS_EN, columns=CLASS_LABELS_EN)

plt.figure(figsize=(8, 6))
sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', linewidths=.5, linecolor='black', 
            annot_kws={"size": 14})
plt.title('Confusion Matrix (Test Data)', fontsize=16)
plt.ylabel('True Label', fontsize=14)
plt.xlabel('Predicted Label', fontsize=14)
plt.show()

# ۳. نمودار ROC (Receiver Operating Characteristic)
plt.figure(figsize=(10, 7))
auc_scores = []

# محاسبه و ترسیم ROC برای هر کلاس (One-vs-Rest)
for i in range(len(LABELS)):
    try:
        fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_prob[:, i])
        auc_score = df_class_metrics.iloc[i]['AUC (OVR)'] 
        plt.plot(fpr, tpr, color=COLORS[i], label=f'{CLASS_LABELS_EN[i]} (AUC = {auc_score:.2f})')
    except Exception as e:
        print(f"⚠️ اخطار: خطایی در ترسیم ROC کلاس {CLASS_LABELS_EN[i]} رخ داد: {e}")

# ترسیم میانگین ماکرو (فقط در صورت وجود)
if not np.isnan(auc_roc_ovr_plot):
    mean_fpr = np.linspace(0.0, 1.0, 100) 
    # میانگین‌گیری از منحنی‌های ROC با استفاده از درون‌یابی
    mean_tpr = np.mean([np.interp(mean_fpr, *roc_curve(y_test_binarized[:, i], y_prob[:, i])[:2]) for i in range(len(LABELS))], axis=0)
    mean_tpr[0] = 0.0
    plt.plot(mean_fpr, mean_tpr, color='black', linestyle='--', label=f'Macro Average (AUC = {auc_roc_ovr_plot:.2f})', linewidth=2)

plt.plot([0, 1], [0, 1], 'r--', label='Random Classifier')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate', fontsize=12)
plt.ylabel('True Positive Rate', fontsize=12)
plt.title('ROC Curve per Class (One-vs-Rest Strategy)', fontsize=16)
plt.legend(loc="lower right")
plt.show()


# ۴. نمودار کالیبراسیون (Calibration Curve)
plt.figure(figsize=(10, 7))
plt.plot([0, 1], [0, 1], "r--", label="Perfectly Calibrated")
brier_scores = []

for i in range(len(LABELS)):
    y_true_class = (y_test == LABELS[i])
    y_prob_class = y_prob[:, i]
    
    brier = brier_score_loss(y_true_class, y_prob_class)
    brier_scores.append(brier)
    
    fraction_of_positives, mean_predicted_value = calibration_curve(
        y_true_class, y_prob_class, n_bins=10
    )
    
    plt.plot(mean_predicted_value, fraction_of_positives, "s-", 
             label=f'{CLASS_LABELS_EN[i]} (Brier: {brier:.2f})', color=COLORS[i])

mean_brier = np.mean(brier_scores)
plt.text(0.1, 0.8, f'Mean Brier Score: {mean_brier:.2f}', fontsize=12, color='black', transform=plt.gca().transAxes)
plt.text(0.1, 0.75, f'Overall Log Loss: {logloss:.4f}', fontsize=12, color='black', transform=plt.gca().transAxes)


plt.ylabel("Fraction of Positives", fontsize=12)
plt.xlabel("Mean Predicted Probability", fontsize=12)
plt.title("Calibration Curve (Predicted vs. True Probability)", fontsize=16)
plt.legend(loc="lower right")
plt.show()

print("\n✅ تمامی نمودارهای درخواستی تولید و نمایش داده شدند.")
print("زمان کل اجرای سلول ۴ (ترسیم نمودارها):")

print("\nزمان کل اجرای سلول ۱ (آماده‌سازی داده):")
