import pandas as pd
import re
from google.colab import files
import io
from transformers import AutoModel, AutoTokenizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, mean_squared_error
from sklearn.preprocessing import label_binarize
from sklearn.calibration import CalibrationDisplay
from scipy.stats import chi2_contingency
from imblearn.over_sampling import SMOTE
import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch

# زمان‌سنجی برای پردازش
start_time = time.time()

# تعریف واژگان دسته اول و دوم
category_1 = [
    "خودکشی", "آماده خودکشی", "نقشه خودکشی", "مرگ خودخواسته", "می‌خواهم خودم را بکشم",
    "تا ابد بخوابم", "هیچوقت بیدار نشم", "به زندگی‌ام پایان می‌دهم", "نمی‌تونم ادامه بدم",
    "نمی‌خوام زنده باشم", "خودسوزی", "زندگی برای من تمام شده", "خودم را خلاص کنم",
    "خودمو خلاص کنم", "خودم رو خلاص کنم", "چرا نباید خودم را بکشم؟", "#خودکشی"
]

category_2 = [
    "افسردگی", "دارم عذاب می‌کشم", "هیچ امیدی ندارم", "از خودم متنفرم", "از خودم بدم میاد",
    "چیزی برای از دست دادن ندارم", "از زندگی خسته‌ام", "تنها می‌میرم", "مرگ", "درد", "ناامیدی",
    "تنهایی", "غم", "بی‌ارزش", "خستگی", "فشار رومه", "استرس", "استرس دارم", "همه چیز بی‌فایده است",
    "هیچکس مرا نمی‌فهمد", "از همه چیز متنفرم", "#افسردگی", "#تنهایی", "#درد", "#غم", "#ناامیدی"
]

# کلمات زمینه برای تفکیک خودزنی واقعی و استعاری
serious_context = [
    "قرص", "خون", "آسیب", "گریه", "جیغ", "درد", "افسردگی", "خودکشی", "مرگ", "ناامیدی"
]
humorous_context = [
    "😂", "😁", "🤣", "سوتی", "کصخل", "خنده", "شوخی", "فان", "ههه", "هاها"
]

# تابع برای لیبل‌گذاری با روش واژگان کلیدی
def label_tweet(tweet):
    tweet = str(tweet).lower()
    
    if "خودزنی" in tweet:
        if any(re.search(r'\b' + re.escape(word) + r'\b', tweet) for word in serious_context):
            return 2, "دسته اول", "خودزنی", 0.9
        elif any(re.search(r'\b' + re.escape(word) + r'\b', tweet) for word in humorous_context) or "😂" in tweet or "😁" in tweet:
            return 0, "هیچ‌کدام", "خودزنی", 0.3
        else:
            return 0, "هیچ‌کدام", "خودزنی", 0.3
    
    for word in category_1:
        if re.search(r'\b' + re.escape(word) + r'\b', tweet):
            return 2, "دسته اول", word, 0.9
    
    for word in category_2:
        if re.search(r'\b' + re.escape(word) + r'\b', tweet):
            return 1, "دسته دوم", word, 0.65
    
    return 0, "هیچ‌کدام", "هیچ‌کدام", 0.3

# تابع برای محاسبه Specificity
def specificity_score(y_true, y_pred, classes):
    cm = confusion_matrix(y_true, y_pred, labels=classes)
    specificity_per_class = []
    for i in range(len(classes)):
        tn = np.sum(cm) - np.sum(cm[i, :]) - np.sum(cm[:, i]) + cm[i, i]
        fp = np.sum(cm[:, i]) - cm[i, i]
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        specificity_per_class.append(specificity)
    return np.mean(specificity_per_class)

# تابع برای تولید امبدینگ با ParsBERT
def get_parsbert_embeddings(texts, model, tokenizer, batch_size=32, device='cuda' if torch.cuda.is_available() else 'cpu'):
    model.to(device)
    model.eval()
    embeddings = []
    
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]
        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=128)
        inputs = {key: val.to(device) for key, val in inputs.items()}
        
        with torch.no_grad():
            outputs = model(**inputs)
            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # CLS token
        embeddings.append(batch_embeddings)
    
    return np.vstack(embeddings)

# نصب کتابخانه‌ها
!pip install transformers imbalanced-learn scikit-learn matplotlib seaborn

# آپلود فایل آموزشی
print("لطفاً فایل آموزشی 'labeled_tweets_3000.xlsx' را آپلود کنید:")
uploaded_train = files.upload()

if not uploaded_train:
    raise ValueError("فایل آموزشی آپلود نشد. لطفاً فایل 'labeled_tweets_3000.xlsx' را آپلود کنید.")

# خواندن فایل آموزشی
train_file = list(uploaded_train.keys())[0]
df_train = pd.read_excel(io.BytesIO(uploaded_train[train_file]))

# اطمینان از وجود ستون‌های مورد نیاز
required_columns = ['متن توییت', 'برچسب']
if not all(col in df_train.columns for col in required_columns):
    raise ValueError("ستون‌های 'متن توییت' یا 'برچسب' در فایل آموزشی یافت نشد.")

# آماده‌سازی داده‌های آموزشی
X_train_texts = df_train['متن توییت'].astype(str).tolist()
y_train = df_train['برچسب'].astype(int).values

# بارگذاری مدل و توکنایزر ParsBERT
model_name = "HooshvareLab/bert-fa-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)

# تبدیل متن‌های آموزشی به امبدینگ
print("در حال تولید امبدینگ‌های آموزشی با ParsBERT...")
X_train_embeddings = get_parsbert_embeddings(X_train_texts, model, tokenizer, batch_size=32)

# اعمال SMOTE برای رفع نامتوازنی
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_embeddings, y_train)

# آموزش مدل طبقه‌بند RandomForest
classifier = RandomForestClassifier(n_estimators=100, random_state=42)
classifier.fit(X_train_balanced, y_train_balanced)

# آپلود فایل جدید
print("لطفاً فایل جدید 'new_tweets.xlsx' را آپلود کنید:")
uploaded_new = files.upload()

if not uploaded_new:
    raise ValueError("فایل جدید آپلود نشد. لطفاً فایل 'new_tweets.xlsx' را آپلود کنید.")

# خواندن فایل جدید
new_file = list(uploaded_new.keys())[0]
df_new = pd.read_excel(io.BytesIO(uploaded_new[new_file]))

# اطمینان از وجود ستون "متن توییت"
if 'متن توییت' not in df_new.columns:
    raise ValueError("ستون 'متن توییت' در فایل جدید یافت نشد.")

# تبدیل متن‌های جدید به امبدینگ
print("در حال تولید امبدینگ‌های داده‌های جدید با ParsBERT...")
X_new_texts = df_new['متن توییت'].astype(str).tolist()
X_new_embeddings = get_parsbert_embeddings(X_new_texts, model, tokenizer, batch_size=32)

# پیش‌بینی لیبل‌ها با مدل
y_pred_new = classifier.predict(X_new_embeddings)

# اصلاح برچسب‌ها برای خودزنی استعاری
for i, (tweet, label) in enumerate(zip(X_new_texts, y_pred_new)):
    tweet_lower = tweet.lower()
    if "خودزنی" in tweet_lower:
        if any(word in tweet_lower for word in humorous_context) or "😂" in tweet_lower or "😁" in tweet_lower:
            y_pred_new[i] = 0  # خودزنی استعاری: برچسب 0

# لیبل‌گذاری با روش واژگان کلیدی برای مقایسه
y_ref_new = []
ref_categories = []
ref_matched_words = []
ref_similarities = []
for tweet in X_new_texts:
    label, category, matched_word, similarity = label_tweet(tweet)
    y_ref_new.append(label)
    ref_categories.append(category)
    ref_matched_words.append(matched_word)
    ref_similarities.append(similarity)
y_ref_new = np.array(y_ref_new)

# محاسبه معیارهای ارزیابی
accuracy = accuracy_score(y_ref_new, y_pred_new)
precision_weighted = precision_score(y_ref_new, y_pred_new, average='weighted', zero_division=0)
recall_weighted = recall_score(y_ref_new, y_pred_new, average='weighted', zero_division=0)
f1_weighted = f1_score(y_ref_new, y_pred_new, average='weighted', zero_division=0)
precision_macro = precision_score(y_ref_new, y_pred_new, average='macro', zero_division=0)
recall_macro = recall_score(y_ref_new, y_pred_new, average='macro', zero_division=0)
f1_macro = f1_score(y_ref_new, y_pred_new, average='macro', zero_division=0)
specificity_macro = specificity_score(y_ref_new, y_pred_new, classes=[0, 1, 2])

# محاسبه AUC
y_ref_bin = label_binarize(y_ref_new, classes=[0, 1, 2])
y_pred_prob = classifier.predict_proba(X_new_embeddings)
auc = roc_auc_score(y_ref_bin, y_pred_prob, multi_class='ovr', average='weighted')

# محاسبه RMSE
rmse = np.sqrt(mean_squared_error(y_ref_new, y_pred_new))

# محاسبه Confusion Matrix
cm = confusion_matrix(y_ref_new, y_pred_new, labels=[0, 1, 2])

# رسم و ذخیره منحنی ROC
plt.figure(figsize=(8, 6))
for i in range(3):
    fpr, tpr, _ = roc_curve(y_ref_bin[:, i], y_pred_prob[:, i])
    plt.plot(fpr, tpr, label=f'ROC منحنی کلاس {i} (AUC = {roc_auc_score(y_ref_bin[:, i], y_pred_prob[:, i]):.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('نرخ مثبت کاذب (False Positive Rate)')
plt.ylabel('نرخ مثبت واقعی (True Positive Rate)')
plt.title('منحنی ROC برای هر کلاس')
plt.legend(loc="lower right")
plt.savefig('roc_curve.png')
plt.show()
files.download('roc_curve.png')

# رسم و ذخیره ماتریس کالیبراسیون
plt.figure(figsize=(8, 6))
for i in range(3):
    disp = CalibrationDisplay.from_predictions(y_ref_bin[:, i], y_pred_prob[:, i], n_bins=10, name=f'کلاس {i}')
    disp.plot(ax=plt.gca(), name=f'کلاس {i}')
plt.title('ماتریس کالیبراسیون برای هر کلاس')
plt.savefig('calibration_plot.png')
plt.show()
files.download('calibration_plot.png')

# رسم و ذخیره ماتریس درهم‌ریختگی
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1', '2'], yticklabels=['0', '1', '2'])
plt.xlabel('برچسب پیش‌بینی‌شده')
plt.ylabel('برچسب مرجع (واژگان کلیدی)')
plt.title('ماتریس درهم‌ریختگی')
plt.savefig('confusion_matrix.png')
plt.show()
files.download('confusion_matrix.png')

# آزمون آماری معناداری (Chi-Square)
cm_flat = cm.ravel()
if len(cm_flat) == 9:  # اطمینان از ماتریس 3x3
    chi2, p_value, _, _ = chi2_contingency(cm)
else:
    chi2, p_value = np.nan, np.nan

# چاپ معیارهای ارزیابی
print("معیارهای ارزیابی مدل روی داده‌های جدید (مقایسه با لیبل‌های واژگان کلیدی):")
print(f"1. دقت (Accuracy): {accuracy:.2%}")
print(f"2. دقت مثبت (Precision, weighted): {precision_weighted:.2%}")
print(f"3. یادآوری (Recall, weighted): {recall_weighted:.2%}")
print(f"4. امتیاز F1 (F1-Score, weighted): {f1_weighted:.2%}")
print(f"5. دقت مثبت (Precision, macro): {precision_macro:.2%}")
print(f"6. یادآوری (Recall, macro): {recall_macro:.2%}")
print(f"7. امتیاز F1 (F1-Score, macro): {f1_macro:.2%}")
print(f"8. ویژگی (Specificity, macro): {specificity_macro:.2%}")
print(f"AUC (weighted): {auc:.2%}")
print(f"RMSE: {rmse:.4f}")
print("\nماتریس درهم‌ریختگی (Confusion Matrix):")
print(cm)
print(f"\nآزمون Chi-Square: مقدار chi2 = {chi2:.2f}, مقدار p-value = {p_value:.4f}")
print("\nگزارش کامل طبقه‌بندی:")
print(classification_report(y_ref_new, y_pred_new, zero_division=0))

# ایجاد دیتافریم خروجی
df_output = df_new.copy()[['متن توییت']]
df_output['برچسب'] = y_pred_new
df_output['مجموعه واژگان'] = ref_categories
df_output['واژه/عبارت مشابه'] = ref_matched_words
df_output['آستانه شباهت'] = ref_similarities

# ذخیره فایل اکسل خروجی
output_excel = "new_labeled_tweets.xlsx"
df_output.to_excel(output_excel, index=False)

# ذخیره فایل متنی با جداکننده |
output_text = "new_labeled_tweets.txt"
df_output.to_csv(output_text, sep='|', index=False, encoding='utf-8')

print(f"فایل اکسل ذخیره شد: {output_excel}")
print(f"فایل متنی ذخیره شد: {output_text}")
print(f"زمان کل پردازش: {time.time() - start_time:.2f} ثانیه")

# دانلود خودکار فایل‌های خروجی
files.download(output_excel)
files.download(output_text)
